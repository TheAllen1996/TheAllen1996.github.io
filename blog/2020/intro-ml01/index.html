<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Machine Learning - 01 Introduction | Jingye(Allen) Wang</title> <meta name="author" content="Jingye(Allen) Wang"> <meta name="description" content="A brief discussion on frequentist and bayesian views. Get familiar with Gaussian distribution from PDF and statistics perspectives."> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8D%82&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://theallen1996.github.io/blog/2020/intro-ml01/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jingye(Allen) </span>Wang</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Gallery</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Machine Learning - 01 Introduction</h1> <p class="post-meta">September 28, 2020</p> <p class="post-tags"> <a href="/blog/2020"> <i class="fas fa-calendar fa-sm"></i> 2020 </a>   ·   <a href="/blog/tag/machine-learning"> <i class="fas fa-tag fa-sm"></i> Machine-Learning</a>   </p> </header> <article class="post-content"> <p><em>The notes are based on the <a href="https://github.com/shuhuai007/Machine-Learning-Session" rel="external nofollow noopener" target="_blank">session</a>. Many thanks to the great work.</em></p> <ul id="markdown-toc"> <li><a href="#0-motivation" id="markdown-toc-0-motivation">0. Motivation</a></li> <li><a href="#1-frequentist-vs-bayesian" id="markdown-toc-1-frequentist-vs-bayesian">1. Frequentist vs Bayesian</a></li> <li><a href="#2maximum-likelihood-estimation-on-gaussian-distribution" id="markdown-toc-2maximum-likelihood-estimation-on-gaussian-distribution">2.Maximum Likelihood Estimation on Gaussian Distribution</a></li> <li><a href="#3-gaussian-distribution" id="markdown-toc-3-gaussian-distribution">3. Gaussian Distribution</a></li> <li> <a href="#4-calculations-on-gaussian" id="markdown-toc-4-calculations-on-gaussian">4. Calculations on Gaussian</a> <ul> <li><a href="#41-calculations-on-union-distribution" id="markdown-toc-41-calculations-on-union-distribution">4.1. Calculations on Union Distribution</a></li> <li><a href="#42-calculations-on-marginal-and-conditional-distribution" id="markdown-toc-42-calculations-on-marginal-and-conditional-distribution">4.2 Calculations on Marginal and Conditional Distribution</a></li> </ul> </li> <li><a href="#5-conclusion" id="markdown-toc-5-conclusion">5. Conclusion</a></li> </ul> <h1 id="0-motivation">0. Motivation</h1> <p>After setting up this blog, I actually had no idea about what should I post. I am definitely not good at writing, but still I enjoy it a lot. As I am weak in machine learning and mathematics, for writing and learning, a ‘<em>translation</em>’ work of the <a href="https://github.com/shuhuai007/Machine-Learning-Session" rel="external nofollow noopener" target="_blank">session</a> may be a good start. So here we are!</p> <h1 id="1-frequentist-vs-bayesian">1. Frequentist vs Bayesian</h1> <p>Many machine learning methods can be illustrated in a <em>probabilistic</em> way. We now introduce two mainstream views of interpreting probability: <strong>frequentist</strong> and <strong>bayesian</strong>.</p> <p>Firstly let us consider a simple example. Suppose we have a data \(X=(x_1,x_2,\ldots,x_N)^T\) where \(x_i\) are i.i.d. samples of the random variable \(x\) and is of \(d\) dimensions. Also, we define \(\theta\) be the parameter so that \(x\sim P(x\|\theta)\), and we call \(P(X\|\theta)\) the <em>likelihood</em>.</p> <p><strong>Frequentists</strong>: \(\theta\) is an unknown <em>constant</em>. What they care is how to use the data to infer the value of \(\theta\). The best known approach for that is <strong>maximum likelihood estimation</strong> (MLE):</p> \[\hat{\theta}_\text{MLE}=\arg\max_{\theta}P(X|\theta).\] <blockquote> <p>Many traditional machine learning methods are based on this view. They construct a probabilistic model, then determine a loss function and minimize it by methods like gradient descent.</p> </blockquote> <p><strong>Bayesians</strong>: \(\theta\) is random variable, following distribution \(P(\theta)\), which is called <em>prior distribution</em>, and \(P(\theta\|X)\) is called <em>posterior distribution</em>. Then by <em>Bayes’s theorem</em>, we have <strong>maximum a posteriori</strong> (MAP):</p> \[\hat{\theta}_\text{MAP}=\arg\max_{\theta}P(\theta|X).\] <blockquote> <p>In Bayesian inference, the posterior distribution, rather than the maximum, is the key. However, to determine the distribution sometimes is really hard as it may incur complex calculus:</p> \[P(\theta|X)=\frac{P(X|\theta)\cdot P(\theta)}{\int_{\theta}P(X|\theta)\cdot P(\theta)\text{d}\theta}\] <p>Many powerful and elegant approaches were proposed for this. For examples, MCMC, probabilistic graphical model, <em>etc</em>.</p> </blockquote> <p>I’d like to cite <a href="https://www.probabilisticworld.com/frequentist-bayesian-approaches-inferential-statistics/" rel="external nofollow noopener" target="_blank">this</a> to summary the differences.</p> <p><em>“In short, according to the frequentist definition of probability, only repeatable random events (like the result of flipping a coin) have probabilities. These probabilities are equal to the long-term frequency of occurrence of the events in question. Frequentists don’t attach probabilities to hypotheses or to any fixed but unknown values in general.”</em></p> <p><em>“In contrast, Bayesians view probabilities as a more general concept. As a Bayesian, you can use probabilities to represent the uncertainty in any event or hypothesis. Here, it’s perfectly acceptable to assign probabilities to non-repeatable events.”</em></p> <h1 id="2maximum-likelihood-estimation-on-gaussian-distribution">2.Maximum Likelihood Estimation on Gaussian Distribution</h1> <p>In this section, we will give an example of MLE on Gaussian distribution. Just like what we defined in section 1, there is a data \(X=(x_1,x_2,\ldots,x_N)^T\) where \(x_i\) are i.i.d. samples of the random variable \(x\) and is of \(d=1\) dimension. Thus we have \(X\in\mathbb{R}^{N\times 1}\). We further attach a specific distribution to \(x\) as \(x\sim\mathcal{N}(\mu,\sigma^2)\). The unknown parameter then becomes \(\theta=(\mu,\sigma)\). Now we use MLE method to estimate the parameter:</p> \[\hat{\theta}_\text{MLE}=\arg\max_\theta P(X|\theta)=\arg\max_\theta \log P(X|\theta).\] <blockquote> <p>Given \(x\sim\mathcal{N}(\mu,\sigma^2)\), the PDF of \(x\) is</p> \[p(x|\mu,\sigma)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}.\] </blockquote> <p>As \(x_i,i=1,\ldots,N\) are i.i.d. variables, it follows that</p> \[P(X|\theta)=\prod_{i=1}^NP(x_i|\theta).\] <p>Hence,</p> \[\begin{aligned}\arg\max_\theta\log P(X|\theta)&amp;=\arg\max_\theta\log \prod_{i=1}^N P(x_i|\theta)\\&amp;=\arg\max_\theta\sum_{i=1}^N\log P(x_i|\theta)\\&amp;=\arg\max_\theta\sum_{i=1}^N\log\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\\&amp;=\arg\max_\theta\sum_{i=1}^N\left[\log \frac{1}{\sqrt{2\pi}}+\log\frac{1}{\sigma}-\frac{(x_i-\mu)^2}{2\sigma^2}\right]\\&amp;=\arg\max_\theta\sum_{i=1}^N\left[\log\frac{1}{\sigma}-\frac{(x_i-\mu)^2}{2\sigma^2}\right]\end{aligned},\] <p>which is equivalent to a numerical optimization problem. Denote the term \(\sum_{i=1}^N\left[\log\frac{1}{\sigma}-\frac{(x_i-\mu)^2}{2\sigma^2}\right]\) as \(\mathcal{L}\). The maximum occurs when</p> \[\frac{\partial\mathcal{L}}{\partial\mu}=0,\quad \frac{\partial\mathcal{L}}{\partial\sigma}=0.\] <p>Solving the equations we have</p> \[\mu_\text{MLE}=\frac{1}{N}\sum_{i=1}^N x_i,\quad \sigma^2_\text{MLE}=\frac{1}{N}\sum_{i=1}^N(x_i-\mu_\text{MLE})^2.\] <blockquote> <p>\(\mu_\text{MLE}\) is an <em>unbiased estimation</em> as \(\mathbb{E}[\mu_\text{MLE}]=\mu\), while \(\sigma_\text{MLE}^2\) is a <em>biased estimation</em> since \(\mathbb{E}[\sigma_\text{MLE}^2]=\frac{N-1}{N}\sigma^2\). The bias is incurred by the exploitation on samples rather than the true distribution. Intuitively, the variance of the samples will never be larger than the true distribution since they are totally generated from that!</p> </blockquote> <h1 id="3-gaussian-distribution">3. Gaussian Distribution</h1> <p>Many advanced machine learning techniques, like <em>linear Gaussian model</em>, <em>Kalman filter</em>, <em>P-PCA</em>, <em>etc</em>, involve Gaussian distribution. Therefore it is quite practical to get familiar with Gaussian distribution. In this section, we are trying to explain why the PDF of bivariate Gaussian distribution is shaped by numerous ellipses.</p> <p>Suppose we have a random variable \(x\sim \mathcal{N}(\mu,\Sigma)\) of \(d\) dimensions. Specifically, the definition follows that</p> \[P(x|\mu,\Sigma)=\frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}}e^{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)},\] <p>and</p> \[x=\begin{pmatrix}x_{1}\\x_{2}\\\vdots\\x_{d}\end{pmatrix}_{d\times1},\quad \mu=\begin{pmatrix}\mu_1\\\mu_2\\\vdots\\\mu_{d}\end{pmatrix}_{d\times1},\quad\Sigma=\begin{pmatrix}\sigma_{11}&amp;\sigma_{12}&amp;\cdots&amp;\sigma_{1d}\\\sigma_{21}&amp;\sigma_{22}&amp;\cdots&amp;\sigma_{2d}\\\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\\sigma_{d1}&amp;\sigma_{d2}&amp;\cdots&amp;\sigma_{dd}\end{pmatrix}_{d\times d}.\] <p>As it involves matrix, a simplification will be a wise choice. For simplicity, we use \(\Delta(x)\) to represent \((x-\mu)^T\Sigma^{-1}(x-\mu)\) and suppose the covariance matrix \(\Sigma\) to be positive definite, which is reasonable. By the eigenvalue decomposition and the property of positive definite matrix, \(\Sigma\) can be decomposed as \(\Sigma=U\Lambda U^T\), where \(U=(u_1,u_2,\ldots,u_d)\) is an orthogonal matrix whose columns are the eigenvectors of \(\Sigma\), and \(\Lambda=\text{diag}(\lambda_1,\lambda_2,\ldots,\lambda_d)\) is a diagonal matrix whose entries are the eigenvalues of \(\Sigma\). Then we have</p> \[\begin{aligned}\Sigma^{-1}&amp;=(U\Lambda U^T)^{-1}\\&amp;=(U^T)^{-1}\Lambda^{-1}U^{-1}\\&amp;=U\Lambda^{-1}U^T\\&amp;=(u_1,u_2,\ldots,u_d)\begin{pmatrix}\frac{1}{\lambda_1}&amp;0&amp;\cdots&amp;0\\0&amp;\frac{1}{\lambda_2}&amp;\cdots&amp;0\\\vdots&amp;\vdots&amp;\ddots&amp;0\\0&amp;0&amp;\cdots&amp;\frac{1}{\lambda_d}\end{pmatrix}\begin{pmatrix}u_1\\u_2\\\vdots\\u_d\end{pmatrix}\\&amp;=\begin{pmatrix}\frac{u_1}{\lambda_1},\frac{u_2}{\lambda_2},\ldots,\frac{u_d}{\lambda_d}\end{pmatrix}\begin{pmatrix}u_1\\u_2\\\vdots\\u_d\end{pmatrix}\\&amp;=\sum_{i=1}^d\frac{u_iu_i^T}{\lambda_i}\end{aligned}.\] <p>Plugging it in \(\Delta(x)\), we arrive at</p> \[\begin{aligned}\Delta(x)&amp;=(x-\mu)^T\left(\sum_{i=1}^d\frac{u_iu_i^T}{\lambda_i}\right)(x-\mu)\\&amp;=\sum_{i=1}^d(x-\mu)^Tu_i\frac{1}{\lambda_i}u_i^T(x-\mu)\end{aligned}.\] <p>Before moving on, we take a pause to be acquainted with those notations. Specifically, \((x-\mu)\in\mathbb{R}^{d\times 1}\) as \(x, \mu\in\mathbb{R}^{d\times 1}\). \(u_i\) is the eigenvector of \(\Sigma\) so \(u_i\in\mathbb{R}^{d\times 1}\), while \(\lambda_i\) is the eigenvalue of \(\Sigma\) so \(\lambda_i\in\mathbb{R}\). Therefore \((x-\mu)^Tu_i\in\mathbb{R}\), \(u_i^T(x-\mu)\in\mathbb{R}\) and \(\Delta(x)\in\mathbb{R}\). It should not be surprising. Recall that the PDF</p> \[P(x|\mu,\Sigma)=\frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}}e^{-\frac{1}{2}\Delta(x)}\] <p>represents a probability, which is definitely a real number. Now we introduce \(Y=(y_1,y_2,\ldots,y_d)^T\) where \(y_i=(x-\mu)^Tu_i\). Hence</p> \[\Delta(x)=\sum_{i=1}^dy_i\frac{1}{\lambda_i}y_i^T=\sum_{i=1}^d\frac{y_i^2}{\lambda_i}.\] <p><strong>The PDF of \(x\) is rewritten as</strong></p> \[P(x|\mu,\Sigma)=\alpha e^{-\frac{1}{2}\sum_{i=1}^d y_i^2/\lambda_i},\] <p>where \(\alpha=\frac{1}{(2\pi)^{d/2}\|\Sigma\|^{1/2}}\) is a constant. Now suppose we are trying to determine where \(P(x\|\mu,\Sigma)=\beta\). To make it intuitive, we consider the case \(d=2\), then it follows that</p> \[\begin{alignat*}{3}&amp;&amp; \alpha e^{-\frac{1}{2}\left(\frac{y_1^2}{\lambda_1}+\frac{y_2^2}{\lambda_2}\right)}&amp;=\beta\\\Rightarrow&amp;&amp;\frac{y_1^2}{\lambda_1}+\frac{y_2^2}{\lambda_2}&amp;=2(\ln\alpha-\ln\beta)\\\Rightarrow&amp;&amp;\frac{y_1^2}{a^2}+\frac{y_2^2}{b^2}&amp;=1\end{alignat*},\] <p>where \(a^2=2\lambda_1(\ln\alpha-\ln\beta)\) and \(b^2=2\lambda_2(\ln\alpha-\ln\beta)\), and we finally get <strong>a standard equation of ellipse</strong> with respect to \(y_1\) and \(y_2\)! Actually, the transformation \(y_i=(x-\mu)^Tu_i\) is the projection of \(x\) on \(u_i\). Thus in the coordinate system represented by \(x_1\) and \(x_2\), the ellipse will be changed linearly hence the ellipse will not be so standard. For different \(\beta\), we have ellipses with different major and minor axes, and that is why the graph of bivariate Gaussian distribution looks like it is composed of numerous concentration ellipses.</p> <p><em>PS.</em> The above discussion leaves much correctness proof to be done.</p> <h1 id="4-calculations-on-gaussian">4. Calculations on Gaussian</h1> <p>In this section, all the random variables are Gaussian and we will not touch the complex PDF. Rather, we mainly focus on the statistics, the expectation and the variance, of Gaussian distribution.</p> <h2 id="41-calculations-on-union-distribution">4.1. Calculations on Union Distribution</h2> <p>Suppose \(x\sim\mathcal{N}(\mu, \Sigma)\) is the union distribution of \(x_a\) and \(x_b\), <em>i.e.</em> \(x=(x_a,x_b)^T\). Then the definition follows that</p> \[x=\begin{pmatrix}x_a\\x_b\end{pmatrix}_{d\times1},\quad \mu=\begin{pmatrix}\mu_a\\\mu_b\end{pmatrix}_{d\times1},\quad\Sigma=\begin{pmatrix}\Sigma_{aa}&amp;\Sigma_{ab}\\\Sigma_{ba}&amp;\Sigma_{bb}\end{pmatrix}_{d\times d},\] <p>where</p> \[x_a,\mu_a\in\mathbb{R}^{m\times 1},x_b,\mu_b\in\mathbb{R}^{n\times 1}, m+n=d,\] \[\Sigma_{aa}\in\mathbb{R}^{m\times m}, \Sigma_{ab},\Sigma_{ba}^T\in\mathbb{R}^{m\times n}, \Sigma_{bb}\in\mathbb{R}^{n\times n}.\] <p>The problem in this section is how to derive \(P(x_a)\) and \(P(x_b\|x_a)\), or symmetrically, \(P(x_b)\) and \(P(x_a\|x_b)\) given the union distribution. The derivation of \(P(x_a)\) is quite straightforward:</p> \[\begin{aligned}\mathbb{E}[x_a]&amp;=\mathbb{E}\left[\begin{pmatrix}\mathbf{I}_{m\times m}&amp;\mathbf{0}_{m\times n}\end{pmatrix}\begin{pmatrix}x_a\\x_b\end{pmatrix}\right]\\&amp;=\begin{pmatrix}\mathbf{I}_{m\times m}&amp;\mathbf{0}_{m\times n}\end{pmatrix}\mathbb{E}[x]\\&amp;=\begin{pmatrix}\mathbf{I}_{m\times m}&amp;\mathbf{0}_{m\times n}\end{pmatrix}\begin{pmatrix}\mu_a\\\mu_b\end{pmatrix}\\&amp;=\mu_a\end{aligned},\] <p>and</p> \[\begin{aligned}var[x_a]&amp;=var\left[\begin{pmatrix}\mathbf{I}_{m\times m}&amp;\mathbf{0}_{m\times n}\end{pmatrix}\begin{pmatrix}x_a\\x_b\end{pmatrix}\right]\\&amp;=\begin{pmatrix}\mathbf{I}_{m\times m}&amp;\mathbf{0}_{m\times n}\end{pmatrix}var[x]\begin{pmatrix}\mathbf{I}_{m\times m}\\\mathbf{0}_{n\times m}\end{pmatrix}\\&amp;=\begin{pmatrix}\mathbf{I}_{m\times m}&amp;\mathbf{0}_{m\times n}\end{pmatrix}\begin{pmatrix}\Sigma_{aa}&amp;\Sigma_{ab}\\\Sigma_{ba}&amp;\Sigma_{bb}\end{pmatrix}\begin{pmatrix}\mathbf{I}_{m\times m}\\\mathbf{0}_{n\times m}\end{pmatrix}\\&amp;=\Sigma_{aa}\end{aligned}.\] <p>Thus, we have \(x_a\sim\mathcal{N}(\mu_a,\Sigma_{aa})\), and similarly, \(x_b\sim\mathcal{N}(\mu_b,\Sigma_{bb})\). For the conditional probabilities \(P(x_b\|x_a)\), we first define variables</p> \[x_{b\cdot a}=x_b-\Sigma_{ba}\Sigma^{-1}_{aa}x_a,\] \[\mu_{b\cdot a}=\mu_b-\Sigma_{ba}\Sigma^{-1}_{aa}\mu_a,\] <p>and</p> \[\Sigma_{bb\cdot a}=\Sigma_{bb}-\Sigma_{ba}\Sigma^{-1}_{aa}\Sigma_{ab}.\] <p>The term \(\Sigma_{bb\cdot a}\) is also the <em>Schur complement</em> of \(\Sigma_{aa}\) of the matrix \(\Sigma\). Then it follows that</p> \[\begin{aligned}\mathbb{E}[x_{b\cdot a}]&amp;=\mathbb{E}\left[\begin{pmatrix}-\Sigma_{ba}\Sigma_{aa}^{-1}&amp;\mathbf{I}_{n\times n}\end{pmatrix}\begin{pmatrix}x_a\\x_b\end{pmatrix}\right]\\&amp;=\begin{pmatrix}-\Sigma_{ba}\Sigma_{aa}^{-1}&amp;\mathbf{I}_{n\times n}\end{pmatrix}\mathbb{E}[x]\\&amp;=\begin{pmatrix}-\Sigma_{ba}\Sigma_{aa}^{-1}&amp;\mathbf{I}_{n\times n}\end{pmatrix}\begin{pmatrix}\mu_a\\\mu_b\end{pmatrix}\\&amp;=\mu_{b\cdot a}\end{aligned},\] <p>and</p> \[\begin{aligned}var[x_{b\cdot a}]&amp;=var\left[\begin{pmatrix}-\Sigma_{ba}\Sigma_{aa}^{-1}&amp;\mathbf{I}_{n\times n}\end{pmatrix}\begin{pmatrix}x_a\\x_b\end{pmatrix}\right]\\&amp;=\begin{pmatrix}-\Sigma_{ba}\Sigma_{aa}^{-1}&amp;\mathbf{I}_{n\times n}\end{pmatrix}var[x]\begin{pmatrix}-\Sigma_{aa}^{-1}\Sigma_{ba}^T\\\mathbf{I}_{n\times n}\end{pmatrix}\\&amp;=\begin{pmatrix}-\Sigma_{ba}\Sigma_{aa}^{-1}&amp;\mathbf{I}_{n\times n}\end{pmatrix}\begin{pmatrix}\Sigma_{aa}&amp;\Sigma_{ab}\\\Sigma_{ba}&amp;\Sigma_{bb}\end{pmatrix}\begin{pmatrix}-\Sigma_{aa}^{-1}\Sigma_{ba}^T\\\mathbf{I}_{n\times n}\end{pmatrix}\\&amp;=\Sigma_{bb\cdot a}\end{aligned}.\] <p>Hence we have \(x_{b\cdot a}\sim\mathcal{N}(\mu_{b\cdot a},\Sigma_{bb\cdot a})\). Before showing the relation between \(x_{b\cdot a}\) and \(x_b\|x_a\), we introduce a helpful theorem.</p> <p><strong>Theorem</strong>:<em>If</em> \(x\sim\mathcal{N}(\mu,\Sigma)\), <em>then</em> \(Mx\perp Nx\iff M\Sigma N=\mathbf{0}.\)</p> <p><em>Proof:</em> According to the property of Gaussian, \(Mx\sim\mathcal{N}(M\mu,M\Sigma M^T)\) and \(Nx\sim\mathcal{N}(N\mu,N\Sigma N^T)\). Further,</p> \[\begin{aligned}Cov(Mx,Nx)&amp;=\mathbb{E}[(Mx-M\mu)(Nx-N\mu)^T]\\&amp;=M\mathbb{E}[(x-\mu)(x-\mu)^T]N\\&amp;=M\Sigma N^T.\end{aligned}\] <p>For Gaussian distribution, uncorrelation implies independence. Therefore \(M\Sigma N^T=\mathbf{0}\iff Mx\perp Nx.\tag*{\blacksquare}\)</p> <p>Back to our case, we have</p> \[x_{b\cdot a}=\underbrace{\begin{pmatrix}-\Sigma_{ba}\Sigma_{aa}^{-1}&amp;\mathbf{I}\end{pmatrix}}_M\underbrace{\begin{pmatrix}x_a\\x_b\end{pmatrix}}_x,\qquad x_a=\underbrace{\begin{pmatrix}\mathbf{I}&amp;\mathbf{0}\end{pmatrix}}_{N}\underbrace{\begin{pmatrix}x_a\\x_b\end{pmatrix}}_x.\] <p>Check \(M\Sigma N\):</p> \[\begin{aligned}M\Sigma N&amp;=\begin{pmatrix}-\Sigma_{ba}\Sigma_{aa}^{-1}&amp;\mathbf{I}\end{pmatrix}\begin{pmatrix}\Sigma_{aa}&amp;\Sigma_{ab}\\\Sigma_{ba}&amp;\Sigma_{bb}\end{pmatrix}\begin{pmatrix}\mathbf{I}\\\mathbf{0}\end{pmatrix}\\&amp;=\begin{pmatrix}\mathbf{0}&amp; \Sigma_{bb}-\Sigma_{ba}\Sigma_{aa}^{-1}\Sigma_{ab}\end{pmatrix}\begin{pmatrix}\mathbf{I}\\\mathbf{0}\end{pmatrix}\\&amp;=\mathbf{0}\end{aligned}.\] <p>Thus \(x_{b\cdot a}\perp x_a\), which means \(x_{b\cdot a}\|x_a=x_{b\cdot a}\). According to our definition, we finally arrive at</p> \[\begin{aligned}x_b|x_a&amp;=x_{b\cdot a}|x_a+\Sigma_{ba}\Sigma_{aa}^{-1}x_a|x_a\\&amp;=x_{b\cdot a}+\Sigma_{ba}\Sigma_{aa}^{-1}x_a\end{aligned}.\] <p>There is a little abuse of notation: the term \(x_a\) after \(\|\) is a sample of \(x_a\) rather than a random variable. One should notice that \(x_a\) below is constant. Therefore,</p> \[\mathbb{E}[x_b|x_a]=\mathbb{E}[x_{b\cdot a}]+\Sigma_{ba}\Sigma_{aa}^{-1}x_a=\mu_{b\cdot a}+\Sigma_{ba}\Sigma_{aa}^{-1}x_a,\] <p>and</p> \[var[x_b|x_a]=var[x_{b\cdot a}]+0=\Sigma_{bb\cdot a}.\] <p>Removing all the extra variables we defined, we have</p> \[x_b|x_a\sim\mathcal{N}(\mu_b+\Sigma_{ba}\Sigma_{aa}^{-1}(x_a-\mu_a), \Sigma_{bb}-\Sigma_{ba}\Sigma^{-1}_{aa}\Sigma_{ab}),\] <p>and the case for \(x_a\|x_b\) is similar.</p> <h2 id="42-calculations-on-marginal-and-conditional-distribution">4.2 Calculations on Marginal and Conditional Distribution</h2> <p>In this section, the problem is deriving \(P(y)\) and \(P(x\|y)\) given \(P(x)\) and \(P(y\|x)\). For example, let’s say, \(x\sim\mathcal{N}(\mu, \Sigma)\) and \(y\|x\sim\mathcal{N}(Ax+b,L^{-1})\), which is common in <em>linear Gaussian model</em>. The abuse of notation here is the same as we mentioned above: the \(x\ (y)\) in \(y\|x\ (x\|y)\) represents a sample rather than a random variable. Now we define \(y=Ax+b+\varepsilon\), where \(\varepsilon\sim\mathcal{N}(0,L^{-1})\) is the noise in practice. Then we have</p> \[\mathbb{E}[y]=\mathbb{E}[Ax+b+\varepsilon]=A\mu+b,\] <p>and</p> \[var[y]=var[Ax+b]+var[\varepsilon]=A\Sigma A^T+L^{-1}.\] <p>Therefore \(y\sim\mathcal{N}(A\mu+b, A\Sigma A^T+L^{-1})\). For the distribution of \(x\|y\), we can refer to the conclusion of section 4.1. Introducing a union variable \(z=(x,y)^T\), we obtain</p> \[z\sim\mathcal{N}\left(\begin{pmatrix}\mu\\A\mu+b\end{pmatrix},\begin{pmatrix}\Sigma&amp;Cov(x,y)\\Cov(y,x)&amp;A\Sigma A^T+L^{-1}\end{pmatrix}\right).\] <p>By the property of covariance, we have \(Cov(y,x)=Cov(x,y)^T\). Further,</p> \[\begin{aligned}Cov(x,y)&amp;=\mathbb{E}[(x-\mu)(y-A\mu-b)^T]\\&amp;=\mathbb{E}[(x-\mu)(Ax+b+\varepsilon-A\mu-b)^T]\\&amp;=\mathbb{E}[(x-\mu)(Ax-A\mu)^T]+\mathbb{E}[(x-\mu)\varepsilon^T]\\&amp;=\mathbb{E}[(x-\mu)(x-\mu)^T]A^T+0\\&amp;=var(x)A^T\\&amp;=\Sigma A^T\end{aligned}.\] <p>With the known union distribution \(z=(x,y)^T\) and \(P(y)\), we can derive \(P(x\|y)\) by the method mentioned in section 4.1.</p> <h1 id="5-conclusion">5. Conclusion</h1> <p>In this post, we talk a lot about Gaussian distribution as it plays an important role in machine learning. Also, we are trying to get familar with those mathematical things.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Jingye(Allen) Wang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: December 10, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-PD575TTWH8"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-PD575TTWH8");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>